## v0.21.0 (2024-12-02)

### Features

* Support connecting to llamafile model backend.
* Display **Open** / **Closed** state for issues / pull requests in Answer Engine context card.
* Support deleting the entire thread in Answer Engine.
* Add rate limiter options for HTTP-powered model backends.

### Fixed and Improvements

* Fixed a panic that occurred when specifying a local model ([#3464](https://github.com/TabbyML/tabby/issues/3464))
* Add pagination to Answer Engine threads.
* Fix Vulkan binary distributions.
* Improve the retry logic for chunk embedding computation in indexing job.
