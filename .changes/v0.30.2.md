## v0.30.2 (2025-07-31)

### Notice

* This is a patch release, please also check [the full release note](https://github.com/TabbyML/tabby/releases/tag/v0.30.0) for 0.30.

### Fixed and Improvements

* Use 0.7.3 sqlx to avoid database pool timeout. [#4328](https://github.com/TabbyML/tabby/pull/4328)
* Bump llama.cpp to b6047. [#4330](https://github.com/TabbyML/tabby/pull/4330)
* Expose the Flash Attention LLAMA flag as an environment variable. [#4323](https://github.com/TabbyML/tabby/pull/4323)
