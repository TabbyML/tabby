---
sidebar_position: 1
---

# Docker Compose
This guide explains how to launch Tabby using docker-compose.

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs>
  <TabItem value="cuda" label="CUDA">


  For CUDA support in Tabby, install the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).
  After installation, you can start Tabby with the following `docker-compose.yml`:

```yaml title="docker-compose.yml"
version: '3.5'

services:
  tabby:
    restart: always
    image: registry.tabbyml.com/tabbyml/tabby
    command: serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct --device cuda
    volumes:
      - "$HOME/.tabby:/data"
    ports:
      - 8080:8080
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

  </TabItem>
  <TabItem value="cpu" label="CPU">

```yaml title="docker-compose.yml"
version: '3.5'

services:
  tabby:
    restart: always
    image: registry.tabbyml.com/tabbyml/tabby
    entrypoint: /opt/tabby/bin/tabby-cpu
    command: serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct
    environment:
     - LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/compat:$LD_LIBRARY_PATH #Workaround to run in cpu mode, see see https://github.com/TabbyML/tabby/issues/2634#issuecomment-2244530283
    volumes:
      - "$HOME/.tabby:/data"
    ports:
      - 8080:8080
```

  </TabItem>
</Tabs>

