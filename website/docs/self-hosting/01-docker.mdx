# Docker

There is a supplied docker image to make deploying a server as a container easier.

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## CPU

<Tabs>
  <TabItem value="shell" label="Shell" default>

  ```bash title="run.sh"
  docker run -it \
    -p 8080:8080 -v $HOME/.tabby:/data \
    tabbyml/tabby serve --model TabbyML/SantaCoder-1B
  ```

  </TabItem>
  <TabItem value="compose" label="Docker Compose">

```yaml title="docker-compose.yml"
version: '3.5'

services:
  tabby:
    restart: always
    image: tabbyml/tabby
    command: serve --model TabbyML/SantaCoder-1B
    volumes:
      - "$HOME/.tabby:/data"
    ports:
      - 8080:8080
```

  </TabItem>
</Tabs>


## CUDA (requires NVIDIA Container Toolkit)

<Tabs>
  <TabItem value="shell" label="Shell" default>

  ```bash title="run.sh"
  docker run -it \
    --gpus all -p 8080:8080 -v $HOME/.tabby:/data \
    tabbyml/tabby \
    serve --model TabbyML/SantaCoder-1B --device cuda
  ```

  </TabItem>
  <TabItem value="compose" label="Docker Compose">

  ```yaml title="docker-compose.yml"
  version: '3.5'
  services:
    tabby:
      restart: always
      image: tabbyml/tabby
      command: serve --model TabbyML/SantaCoder-1B --device cuda
      volumes:
        - "$HOME/.tabby:/data"
      ports:
        - 8080:8080
      deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: 1
                capabilities: [gpu]
  ```

  </TabItem>
</Tabs>

