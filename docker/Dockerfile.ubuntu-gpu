ARG UBUNTU_VERSION=18.04
ARG CUDA_VERSION=10.0
FROM nvidia/cuda:${CUDA_VERSION}-cudnn7-devel-ubuntu${UBUNTU_VERSION} as builder

ENV TENSORRT_MAJOR_VERSION=6
ENV TENSORRT_VERSION=${TENSORRT_MAJOR_VERSION}.0.1

RUN export CUDA_SHORT_VERSION=`echo $CUDA_VERSION | cut -d'.' -f 1,2` && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        apt-transport-https \
        build-essential \
        ca-certificates \
        python3-dev \
        gnupg2 \
        libnvinfer${TENSORRT_MAJOR_VERSION}=${TENSORRT_VERSION}-1+cuda${CUDA_SHORT_VERSION} \
        libnvinfer-dev=${TENSORRT_VERSION}-1+cuda${CUDA_SHORT_VERSION} \
        wget && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /root

RUN wget https://cmake.org/files/v3.12/cmake-3.12.2-Linux-x86_64.tar.gz
RUN tar xf cmake-3.12.2-Linux-x86_64.tar.gz && \
    rm cmake-3.12.2-Linux-x86_64.tar.gz
ENV PATH=$PATH:/root/cmake-3.12.2-Linux-x86_64/bin

ENV MKL_VERSION=2020
ENV MKL_UPDATE=4
ENV MKL_BUILD=912
RUN wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS-2019.PUB && \
    apt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS-*.PUB && \
    rm GPG-PUB-KEY-INTEL-SW-PRODUCTS-*.PUB && \
    echo "deb https://apt.repos.intel.com/mkl all main" > /etc/apt/sources.list.d/intel-mkl.list && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        intel-mkl-64bit-$MKL_VERSION.$MKL_UPDATE-$MKL_BUILD && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

ENV DNNL_VERSION=1.5.0
ENV DNNL_TAG=v1.5
ENV DNNL_DIR=/root/dnnl
RUN wget https://github.com/oneapi-src/oneDNN/releases/download/${DNNL_TAG}/dnnl_lnx_${DNNL_VERSION}_cpu_gomp.tgz && \
    tar xf dnnl*.tgz && \
    rm dnnl*.tgz && \
    mv dnnl* ${DNNL_DIR}

WORKDIR /root/ctranslate2-dev

COPY third_party third_party
COPY cli cli
COPY include include
COPY src src
COPY CMakeLists.txt .

ARG CXX_FLAGS
ENV CXX_FLAGS=${CXX_FLAGS}
ARG CUDA_NVCC_FLAGS
ENV CUDA_NVCC_FLAGS=${CUDA_NVCC_FLAGS:-"-Xfatbin -compress-all"}
ARG CUDA_ARCH_LIST
ENV CUDA_ARCH_LIST=${CUDA_ARCH_LIST:-"Common"}
ENV CTRANSLATE2_ROOT=/root/ctranslate2

RUN mkdir build && \
    cd build && \
    cmake -DCMAKE_INSTALL_PREFIX=${CTRANSLATE2_ROOT} \
          -DCMAKE_PREFIX_PATH=${DNNL_DIR} -DWITH_DNNL=ON -DOPENMP_RUNTIME=COMP \
          -DWITH_CUDA=ON \
          -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="${CXX_FLAGS}" \
          -DCUDA_NVCC_FLAGS="${CUDA_NVCC_FLAGS}" -DCUDA_ARCH_LIST="${CUDA_ARCH_LIST}" .. && \
    VERBOSE=1 make -j4 && \
    make install

ENV LANG=en_US.UTF-8
COPY README.md .
COPY python python

WORKDIR /root/ctranslate2-dev/python
RUN wget -nv https://bootstrap.pypa.io/get-pip.py && \
    python3 get-pip.py && \
    python3 -m pip --no-cache-dir install -r install_requirements.txt && \
    python3 setup.py bdist_wheel && \
    rm -r build && \
    rm get-pip.py && \
    cp install_requirements.txt /root/ctranslate2/ && \
    python3 setup.py sdist && \
    mv dist/* /root/ctranslate2 && \
    rmdir dist

WORKDIR /root
RUN cp -P ${DNNL_DIR}/lib/*.so* /root/ctranslate2/lib && \
    cp -P $([ $CUDA_VERSION = "10.0.130" ] \
        && echo /usr/local/cuda/lib64/libcublas.so* \
        || echo /usr/lib/x86_64-linux-gnu/libcublas*.so*) \
        /root/ctranslate2/lib && \
    cp -P /usr/lib/x86_64-linux-gnu/libcudnn.so* /root/ctranslate2/lib && \
    cp -P /usr/lib/x86_64-linux-gnu/libnvinfer.so* /root/ctranslate2/lib

FROM nvidia/cuda:${CUDA_VERSION}-base-ubuntu${UBUNTU_VERSION}

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        libgomp1 \
        python3-distutils \
        wget \
        && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

COPY --from=builder /root/ctranslate2 /opt/ctranslate2
RUN wget -nv https://bootstrap.pypa.io/get-pip.py && \
    python3 get-pip.py && \
    python3 -m pip --no-cache-dir install /opt/ctranslate2/*cp3*.whl && \
    rm get-pip.py

WORKDIR /opt

ENV CTRANSLATE2_ROOT=/opt/ctranslate2
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CTRANSLATE2_ROOT/lib

ENTRYPOINT ["/opt/ctranslate2/bin/translate"]
